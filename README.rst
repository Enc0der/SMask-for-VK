======================
üéºüéªüé∫ Symphonic Masks for VK
======================

SymphonicMasks is a monophonic pitch redactor based on convolutional neural network operating on Q-transformed spectrograms form inputs audio-files.

Fratures:

* For training model I've used dataset TinySOL (these sounds were originally recorded at Ircam in Paris (France) between 1996 and 1999, as part of a larger project named Studio On Line (SOL))


  * ... –∞ –∑–¥–µ—Å—å —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–∞–º –¥–∞—Ç–∞—Å–µ—Ç: `dataset
    <https://zenodo.org/record/3685367#.Xo1NVi2ZOuU>`_.


.. contents:: Main information


Running Symphonic Masks
--------

Import necessary libraries using pip install -r '.\requirements.txt'
To run the application type python app.py

--------

Datasets
--------
All sound files are splitted for many files by 25-milliseconds.
Then, every file is converted into spectrogram, which are saved to pitchdf. Then, it runs through the trained model and tune pitchs for the right pitches, mentioned in flutes_notes_frequencies dataframe.


* pitchdf -           dataframe, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –≤ —Å–µ–±–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –∫–∞–∂–¥–æ–π –Ω–æ—Ç—ã –∏ –µ–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: 'A#1').
* notes_frequency -   dataframe, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–æ—Ç—ã('A#1') –∏ –µ–µ —á–∞—Å—Ç–æ—Ç—ã –≤ Hz
* origin_note_table - dataframe, –≤ –∫–æ—Ç–æ—Ä–æ–º —É–∫–∞–∑–∞–Ω—ã –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–æ—Ç—ã('A#') –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –µ–π –æ–∫—Ç–∞–≤–∞(1,2,3 –∏ —Ç.–¥.)
* TinySOL_metadata -  original dataframe TinySOL —Å —É–∫–∞–∑–∞–Ω–∏—è–º–∏ –∞–¥—Ä–µ—Å–æ–≤ —Ñ–∞–π–ª–æ–≤, –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–æ—Ç—ã –∏ —Ç.–¥.
* flutes_notes_frequencies - dataframe with actual notes frequencies for flute


Model
------------

Model used in this profect is a CNN.
The brief spectrograms from center of the audio sample will be used to train the CNN to predict pitch.

Please note
------------
* Symphonic Masks only supports MP4 and MOV videos
* Model trained on 1-channel audio, so if the input video has more channels, it will be first resampled to 1-channel audio.
